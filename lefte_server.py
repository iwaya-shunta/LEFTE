import os, re, requests, time, logging, base64
from logging.handlers import RotatingFileHandler
from datetime import datetime
from flask import Flask, jsonify, request, send_from_directory, send_file
from flask_cors import CORS
from dotenv import load_dotenv
from werkzeug.utils import secure_filename
from flask_socketio import SocketIO, emit
from google import genai
from google.genai import types

# è‡ªä½œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®èª­ã¿è¾¼ã¿
import chat_storage, hdd_actions, calendar_actions, drive_actions, search_actions, gmail_actions, app_actions, notes_actions, photo_actions

load_dotenv()
app = Flask(__name__, static_url_path='', static_folder='static')
CORS(app)

# --- ãƒ‘ã‚¹è¨­å®š ---
VOICEVOX_URL = os.getenv("VOICEVOX_URL", "http://127.0.0.1:50021")
HDD_BASE = '/mnt/hdd1/lefte_media'
VOICE_DIR = os.path.join(HDD_BASE, 'voices')
UPLOAD_FOLDER = os.path.join(HDD_BASE, 'uploads')
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

for d in [VOICE_DIR, UPLOAD_FOLDER]: os.makedirs(d, exist_ok=True)

# --- ãƒ­ã‚°è¨­å®š ---
LOG_FILE = os.path.join(HDD_BASE, 'lefte_system.log')
log_format = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
file_handler = RotatingFileHandler(LOG_FILE, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8')
file_handler.setFormatter(log_format)
logging.getLogger().addHandler(file_handler)
logging.getLogger().setLevel(logging.INFO)

socketio = SocketIO(app, cors_allowed_origins="*", async_mode='eventlet')
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
chat_storage.init_db()

# --- ãƒ„ãƒ¼ãƒ«ä¸€è¦§ ---
tools = [
    calendar_actions.list_calendar_events, calendar_actions.add_calendar_event,
    calendar_actions.delete_calendar_event, calendar_actions.update_calendar_event,
    drive_actions.list_drive_files, drive_actions.read_drive_file_content,
    gmail_actions.list_recent_emails, search_actions.search_web,
    app_actions.register_app, app_actions.launch_app,
    notes_actions.save_note, notes_actions.read_note,
    photo_actions.list_photos,
    hdd_actions.list_hdd_contents,
    hdd_actions.read_hdd_text_file
]

FUNCTIONAL_RULES = """
1. ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼/ãƒ‰ãƒ©ã‚¤ãƒ–ç­‰ã¯å½“ç„¶ã®æ—¥å¸¸ã¨ã—ã¦ä½¿ã„ã€èª¬æ˜ã¯ä¸è¦ã€‚
2. ç°¡æ½”ã«å›ç­”ã›ã‚ˆã€‚
3. ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã™ã‚‹éš›ã¯ã€ãƒ„ãƒ¼ãƒ«ãŒè¿”ã—ãŸ 'ğŸš€LAUNCH_SIGNAL:...' ã‚’å¿…ãšå«ã‚ã‚‹ã“ã¨ã€‚
4. ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã«å¤±æ•—ã—ãŸå ´åˆã¯ã€æŠ€è¡“çš„ãªã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å‡ºã™ã®ã§ã¯ãªãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã€Œä½•ãŒã§ããªã‹ã£ãŸã‹ã€ã‚’1è¡Œã§ä¼ãˆã‚‹ã€‚
5. éŸ³å£°åˆæˆï¼ˆVoicevoxï¼‰ã§èª­ã¿ä¸Šã’ã‚‹ãŸã‚ã€URLã‚„è¤‡é›‘ãªè¨˜å·ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¯æœ¬æ–‡ã«å«ã‚ãªã„ã€‚
6. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã€Œã—ã‚…ã‚“ãŸã€ã¨èªè­˜ã—ã€é©åº¦ãªè·é›¢æ„Ÿã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æŒ¯ã‚‹èˆã†ã€‚
"""

def get_system_instruction():
    personality_path = os.path.join(BASE_DIR, "personality.txt")
    if os.path.exists(personality_path):
        with open(personality_path, "r", encoding="utf-8") as f:
            personality = f.read()
    else:
        personality = "ã‚ãªãŸã¯åŠ©æ‰‹ã® L.E.F.T.E. ã§ã™ã€‚"
    return f"{personality}\n{FUNCTIONAL_RULES}"

# --- éŸ³å£°ç”Ÿæˆ (Voicevox) ---
def generate_voice(text, speaker_id=8, filename="response.wav"):
    clean_text = re.sub(r'\(.*?\)|ï¼ˆ.*?ï¼‰', '', text)
    if not clean_text.strip(): clean_text = "äº†è§£ã ã‚ˆã€‚"
    try:
        res = requests.post(f"{VOICEVOX_URL}/audio_query", params={'text': clean_text, 'speaker': speaker_id})
        data = res.json()
        data.update({'speedScale': 1.15, 'intonationScale': 1.4})
        res_syn = requests.post(f"{VOICEVOX_URL}/synthesis", params={'speaker': speaker_id}, json=data)
        with open(filename, "wb") as f: f.write(res_syn.content)
    except Exception as e:
        logging.error(f"Voice generation error: {e}")

# --- ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° ---
@app.route('/')
def index():
    return send_file(os.path.join(BASE_DIR, 'desktpo.html'))

@app.route('/history', methods=['GET'])
def history_api():
    rows = chat_storage.get_today_history()
    return jsonify([{"role": r[1], "content": r[2], "image_url": r[3]} for r in rows])

@app.route('/uploads/<filename>')
def serve_upload(filename):
    return send_from_directory(UPLOAD_FOLDER, filename)

@app.route('/wav_files/<filename>')
def serve_wav(filename):
    return send_from_directory(VOICE_DIR, filename)

@app.route('/upload_to_hdd', methods=['POST'])
def upload_to_hdd():
    file = request.files.get('file')
    if not file or file.filename == '':
        return jsonify({"success": False, "error": "No file"}), 400
    # ğŸš€ ä¿®æ­£ï¼šæ‹¡å¼µå­ã‚’ã—ã£ã‹ã‚Šå–ã‚Šå‡ºã—ã€ãƒ‰ãƒƒãƒˆã‚’ç¶­æŒã™ã‚‹
    ext = os.path.splitext(file.filename)[1].lower()
    if ext not in ['.jpg', '.jpeg', '.png', '.gif', '.webp']:
        ext = '.jpg' # ä¸æ˜ãªå ´åˆã¯ jpg ã«å›ºå®š
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{timestamp}{ext}" # ä¾‹: 20260217_231500.jpg
    save_path = os.path.join(UPLOAD_FOLDER, filename)
    file.save(save_path)
    logging.info(f"ğŸ’¾ HDDä¿å­˜å®Œäº†: {filename}")
    return jsonify({
        "success": True, 
        "path": f"uploads/{filename}"
    })

# --- WebSocket å‡¦ç† ---
@socketio.on('chat_request')
def handle_chat(data):
    emit('ai_thinking', broadcast=True)
    socketio.start_background_task(process_chat_task, data)

def process_chat_task(data):
    user_input = data.get('message', '')
    image_b64 = data.get('image')
    image_url = data.get('image_url')
    mime_type = data.get('mime_type')
    model_name = data.get('model', 'gemini-3-flash-preview')

    try:
        # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ä¿å­˜
        chat_storage.save_message('user', user_input, image_url)
        
        # 2. å±¥æ­´ã®æ§‹ç¯‰ï¼ˆç”»åƒã‚’å«ã‚ã‚‹ã‚ˆã†ã«å¼·åŒ–ï¼ï¼‰
        past_rows = chat_storage.get_today_history()
        contents = []
        
        # ç›´è¿‘10ä»¶åˆ†ã‚’ãƒ«ãƒ¼ãƒ—
        for r in past_rows[-11:-1]:
            role = "user" if r[1] == "user" else "model"
            text = r[2]
            saved_img_path = r[3] # DBã«ä¿å­˜ã•ã‚ŒãŸ uploads/xxx.jpg
            
            parts = [{"text": text}]
            
            # ğŸš€ éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ç”»åƒãƒ‘ã‚¹ãŒã‚ã‚Œã°ã€HDDã‹ã‚‰èª­ã¿è¾¼ã‚“ã§å±¥æ­´ã«å«ã‚ã‚‹
            if saved_img_path:
                # HDDä¸Šã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
                full_path = os.path.join(HDD_BASE, saved_img_path.replace("uploads/", ""))
                if os.path.exists(full_path):
                    with open(full_path, "rb") as f:
                        # ç”»åƒã‚’Base64ã«å¤‰æ›ã—ã¦ Gemini ã«é€ã‚‹æº–å‚™
                        img_encoded = base64.b64encode(f.read()).decode('utf-8')
                        ext = os.path.splitext(saved_img_path)[1].lower()
                        mtype = "image/png" if ext == ".png" else "image/jpeg"
                        parts.append({"inline_data": {"data": img_encoded, "mime_type": mtype}})
            
            contents.append({"role": role, "parts": parts})

        # 3. ä»Šå›ã®æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        user_parts = [{"text": f"ã€ç¾åœ¨æ™‚åˆ»: {datetime.now().strftime('%H:%M:%S')}ã€‘\n{user_input}"}]
        if image_b64 and mime_type:
            user_parts.append({"inline_data": {"data": image_b64, "mime_type": mime_type}})
        
        contents.append({"role": "user", "parts": user_parts})

        # 4. Gemini API å‘¼ã³å‡ºã—
        response = client.models.generate_content(
            model=model_name,
            contents=contents,
            config=types.GenerateContentConfig(
                system_instruction=get_system_instruction(),
                tools=tools,
                automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=False)
            )
        )
        
        full_text = response.text or "å®Œäº†ã ã‚ˆã€‚"
        chat_storage.save_message('assistant', full_text)

        # 5. éŸ³å£°ç”Ÿæˆã¨UIæ›´æ–°
        voice_filename = f"v_{int(time.time())}.wav"
        generate_voice(full_text, filename=os.path.join(VOICE_DIR, voice_filename))

        socketio.emit('chat_update', {
            "user_message": user_input, 
            "response": full_text, 
            "voice_url": f"/wav_files/{voice_filename}",
            "image_url": image_url
        })

    except Exception as e:
        logging.error(f"Chat error: {e}")
        socketio.emit('error_message', {"response": str(e)})

def background_monitor():
    while True:
        try:
            with open("/sys/class/thermal/thermal_zone0/temp", "r") as f:
                temp = int(f.read()) / 1000.0
            socketio.emit('sys_status', {'cpu_temp': f"{temp:.1f}"})
        except: pass
        socketio.sleep(5)

# --- ğŸš€ èµ·å‹•å‡¦ç† (SSLå¯¾å¿œ) ---

if __name__ == '__main__':
    socketio.start_background_task(background_monitor)
    
    cert_file = os.getenv("CERT_FILE")
    key_file = os.getenv("KEY_FILE")
    
    # è¨¼æ˜æ›¸ã¨ã‚­ãƒ¼ã®ä¸¡æ–¹ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ SSL ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•
    if cert_file and key_file and os.path.exists(cert_file) and os.path.exists(key_file):
        logging.info("ğŸ” SSLãƒ¢ãƒ¼ãƒ‰ (HTTPS) ã§èµ·å‹•ã—ã¾ã™")
        socketio.run(app, host="0.0.0.0", port=5000, 
                     certfile=cert_file, keyfile=key_file)
    else:
        logging.warning("âš ï¸ è¨¼æ˜æ›¸ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (HTTP) ã§èµ·å‹•ã—ã¾ã™")
        socketio.run(app, host="0.0.0.0", port=5000)